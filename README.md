# Mate Assistant

A privacy-first, on-device AI assistant for Android. Mate replaces the default Google Assistant with a fully local LLM that never sends your data to the cloud.

## Features
- **Dual Inference Backend** â€” MediaPipe (TFLite) for Google Gemma models + llama.cpp (GGUF) for Moondream2, SmolVLM, Qwen2-VL, Phi-3.5
- **Vision Models** â€” Moondream2, SmolVLM, and Qwen2-VL can describe images and read text in photos
- **Model Selector** â€” Choose from 6 compatible LLMs in Settings, with vision badges (ğŸ‘ï¸) and engine labels
- **Tool Use** â€” LLM can launch apps (`[LAUNCH:YouTube]`) and search the web (`[SEARCH:query]`) via DuckDuckGo
- **Web Scraping** â€” Send a URL to extract and summarize web content using Jsoup
- **Conversation Compaction** â€” Auto-summarizes chat after 5 exchanges to stay within token limits
- **Encrypted Memory Vault** â€” Securely stores your name, DOB, and family info using Android EncryptedSharedPreferences
- **Persona Engine** â€” Tune personality (Helpful/Funny/Sarcastic/etc.), verbosity, formality, humor, warmth via sliders
- **Voice Output** â€” TTS with male/female voice selection
- **Screen Awareness** â€” Reads the active app's UI via AssistStructure API
- **Response Timing** â€” Shows LLM generation time on each response

## Build & Run

### Prerequisites
- Android Studio Ladybug or newer
- Android SDK 34+
- Android NDK r26+ (for llama.cpp backend)
- CMake 3.22.1+

### Setup
```bash
# Clone with submodules (required for llama.cpp)
git clone --recursive https://github.com/YOUR_USERNAME/android-gemini-replacement.git

# If already cloned without --recursive:
git submodule update --init
```

### Build
1. Open in Android Studio
2. Sync Gradle (Gradle 8.13 configured)
3. Build & Run on device (arm64 only)

### Set as Default Assistant
1. Go to **Settings > Apps > Default Apps > Digital Assistant App**
2. Select **Mate Assistant**
3. Long-press home button or swipe from corners to trigger

## Architecture
```
AICoreClient.kt          â† Routing layer (selects backend per model)
â”œâ”€â”€ LlmInference          â† MediaPipe TFLite (Gemma models)
â”œâ”€â”€ LlamaCppBackend.kt    â† llama.cpp GGUF (via JNI)
â”‚   â””â”€â”€ llama-android.cpp â† C++ JNI bridge
â”œâ”€â”€ ModelConfig.java      â† Model catalog with URLs, backend type, vision flags
â”œâ”€â”€ ToolExecutor.java     â† App launching + DuckDuckGo web search
â”œâ”€â”€ WebScraper.java       â† Jsoup URL content extraction
â””â”€â”€ PreferencesManager.java â† System prompt generation + persona traits
```

## License
MIT
